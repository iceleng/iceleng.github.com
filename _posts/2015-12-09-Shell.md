---
layout: post
title:  ELK相关
categories: [elk]
---
##每分钟采集load和指定名称进程的资源消耗情况的脚本

    #!/bin/bash
    if [ $# -ne 1 ]
    then
      echo "param error"
      exit
    fi
    
    count=`ps aux | grep $1 | grep -v $0 | grep -v grep | wc -l`
    if [ $count -ne 1 ]
    then
      echo "count is :$count, name is $0"
      exit
    fi
    
    printf "[%s %s %s] " `date "+%Y-%m-%d %H:%M:%S %z"`
    printf " %s %s %s " `uptime | awk {'print $8,$9,$10'}`
    printf " %s" $1
    printf " %s %s %s %s %s\n" `ps aux | grep $1 | grep -v $0 | grep -v grep | awk {'print $3,$4,$5,$6,$10'}`

#crontab 的设置如下：
    */1 * * * * bash /home/iceleng/developerTools/logstash-2.1.0/bin/getProcInfo.sh elastic >> /home/iceleng/getProcInfo.log


##logstash定义elasticSearch的模板
保存进 Elasticsearch
<http://udn.yyuap.com/doc/logstash-best-practice-cn/get_start/full_config.html>

##logstash 向elasticsearch写入数据，如何指定多个数据template
<http://blog.csdn.net/zhifeiyu2008/article/details/47720847>
之前在配置从logstash写数据到elasticsearch时，指定单个数据模板没有问题，但是在配置多个数据模板时候，总是不成功，后来找了很多资料，终于找到解决办法，就是要多加一个配置项： template_name ，切该名字必须全部为小写。
参考配置信息：

    output {
            if [type] == "log_01" {
                    elasticsearch {
                            cluster => 'elasticsearch'
                            host =>         'x.x.x.x'
                            index => 'log_01-%{+YYYY-MM-dd}'
                            port => '9300'
                            workers => 1
                            template => "/data/logstash/conf/template_01.json"
                            template_name => "template_01.json"
                            template_overwrite => true
                    }
            }
            if [type] == "log_02" {
                elasticsearch {
                            cluster => 'elasticsearch'
                            host =>         'x.x.x.x'
                            index => 'log_02-%{+YYYY-MM-dd}'
                            port => '9300'
                            workers => 1
                            template => "/data/logstash/conf/template_02.json"
                            template_name => "template_01.json"
                          template_overwrite => true
                    }
            }
    }


##使用 ElasticSearch + LogStash + Kibana 来可视化网络流量，kibanaelasticsearch
http://www.bkjia.com/yjs/991319.html
为了让采集到的数据的类型能被 elasticsearch 正确处理，添加如下模板，自动对所有 logstash_netflow- 开头的索引采取指定的类型解析：

    curl -XPUT http://localhost:9200/_template/logstash_netflow -d '{
        "template" : "logstash_netflow-*",
        "settings": {
          "index.cache.field.type": "soft",
          "index.store.compress.stored": true
        },
        "mappings" : {
            "_default_" : {
               "_all" : {"enabled" : false},
               "properties" : {
                  "@message":     { "index": "analyzed", "type": "string"  },
                  "@source":      { "index": "not_analyzed", "type": "string"  },
                  "@source_host": { "index": "not_analyzed", "type": "string" },
                  "@source_path": { "index": "not_analyzed", "type": "string" },
                  "@tags":        { "index": "not_analyzed", "type": "string" },
                  "@timestamp":   { "index": "not_analyzed", "type": "date" },
                  "@type":        { "index": "not_analyzed", "type": "string" },
                  "netflow": {
                       "dynamic": true,
                       "path": "full",
                       "properties": {
                           "version": { "index": "analyzed", "type": "integer" },
                           "first_switched": { "index": "not_analyzed", "type": "date" },
                           "last_switched": { "index": "not_analyzed", "type": "date" },
                           "direction": { "index": "not_analyzed", "type": "integer" },
                           "flowset_id": { "index": "not_analyzed", "type": "integer" },
                           "flow_sampler_id": { "index": "not_analyzed", "type": "integer" },
                           "flow_seq_num": { "index": "not_analyzed", "type": "long" },
                           "src_tos": { "index": "not_analyzed", "type": "integer" },
                           "tcp_flags": { "index": "not_analyzed", "type": "integer" },
                           "protocol": { "index": "not_analyzed", "type": "integer" },
                           "ipv4_next_hop": { "index": "analyzed", "type": "ip" },
                           "in_bytes": { "index": "not_analyzed", "type": "long" },
                           "in_pkts": { "index": "not_analyzed", "type": "long" },
                           "out_bytes": { "index": "not_analyzed", "type": "long" },
                           "out_pkts": { "index": "not_analyzed", "type": "long" },
                           "input_snmp": { "index": "not_analyzed", "type": "long" },
                           "output_snmp": { "index": "not_analyzed", "type": "long" },
                           "ipv4_dst_addr": { "index": "analyzed", "type": "ip" },
                           "ipv4_src_addr": { "index": "analyzed", "type": "ip" },
                           "dst_mask": { "index": "analyzed", "type": "integer" },
                           "src_mask": { "index": "analyzed", "type": "integer" },
                           "dst_as": { "index": "analyzed", "type": "integer" },
                           "src_as": { "index": "analyzed", "type": "integer" },
                           "l4_dst_port": { "index": "not_analyzed", "type": "long" },
                           "l4_src_port": { "index": "not_analyzed", "type": "long" }
                       },
                       "type": "object"
                   }
                }
            }
       }
    }'
